{
    "collab_server" : "",
    "contents" : "# Evan Henrich\n# January 2017\n# Fred Hutchinson Cancer Research Center\n# Gottardo Lab\n# ehenrich@fredhutch.org\n\n# PURPOSE: generate HAI tables for downstream HIPC Gene Module Analysis using raw data from Immunespace\n\n# NOTES: The original code to perform these operations was developed by Yuri Kotliarov at\n# NIH (yuri.kotliarov@nih.gov).  This version was developed to provide the same functionality as\n# the original in terms of statistical operation, but use data pulled directly from the ImmuneSpace\n# portal at www.immunespace.org instead of data shared among the collaborating labs via a google\n# drive and also to handle all the studies used in the meta-analysis in an automated format.\n\n#***************TESTING ONLY*********************************\n#------Dependencies-------------\n# library(tidyverse)\n# library(hash)\n# library(ImmuneSpaceR)\n# library(data.table)\n# library(stringr)\n\n#*************************************************************\n#------Helper Functions---------\n# Calc median and SD, return as part of list of lists\nmed_sd_calc <- function(prefix, strains, glob_vals, titer_data){\n  suf <- c(\"med\",\"sd\")\n  for(virus in strains){\n    for(s in suf){\n      tar_list <- paste0(prefix,s)\n      tar_col <- paste0(prefix,virus)\n      if(s == \"med\"){\n        glob_vals[[tar_list]][[virus]] <- median(titer_data[[tar_col]], na.rm = TRUE)\n      }else{\n        glob_vals[[tar_list]][[virus]] <- sd(titer_data[[tar_col]], na.rm = TRUE)\n      }\n    }\n  }\n  return(glob_vals)\n}\n\nrobust_med <- function(vec){\n  return(median(vec[!is.na(vec) & !is.infinite(vec)]))\n}\n\nr_mad <- function(vec){\n  robmed <- robust_med(vec)\n  mad <- median(abs(vec - robmed))\n  return(mad)\n}\n\n# Seems computationally costly, but enough edge cases merit checking for valid data before extraction\n# Valid means at least two titers per strain, with one being zero and the other greater than zero.\nsub_check <- function(sub_df, strains){\n  result <- list()\n  for(vir in strains){\n    d_zero <- sub_df[which(sub_df$virus == vir & sub_df$study_time_collected == 0),]\n    d_other <- sub_df[which(sub_df$virus == vir & sub_df$study_time_collected > 0),]\n    if(nrow(d_zero) > 0 & nrow(d_other) > 0){\n      result[[vir]] <- TRUE\n    }else{\n      result[[vir]] <- FALSE\n    }\n  }\n  final <- !(FALSE %in% result)\n  return(final)\n}\n\nmax_select <- function(subid, trg_col){\n  tmp_ls <- list()\n  for(virus in gl_strains){\n    tmp_ls[virus] <- gl_tdata[gl_tdata$subject == subid, paste0(trg_col, virus)]\n  }\n  return(max(unlist(tmp_ls), na.rm = TRUE))\n}\n\n# Method by Yuri Kotliarov to categorize an observation based on low and high percentiles\n# Changed slightly to round fc_res_max values to 7 digits prior to comparison with quantile\n# values which are interpolated and therefore can throw off assignment if intention is to\n# use them as if they are nearest order statistic (similar to type = 3 in quantiles args).\ndiscretize <- function(df, input_col, low_perc, sdy, name){\n  xq <- quantile(df[[input_col]],\n                 c( (low_perc/100), 1 - (low_perc/100) ),\n                 na.rm = T,\n                 type = 7)\n  xd <- \"\"\n  if(sdy == \"SDY67\" && name == \"combined\"){\n    xd <- sapply(df[[input_col]], FUN = function(x){\n      if(is.na(x)){\n        return(NA)\n      }else if(round(x, digits = 7) < round(xq[[1]], digits = 7)){\n        return(0)\n      }else if(round(x, digits = 7) >= round(xq[[2]], digits = 7)){\n        return(2)\n      }else{\n        return(1)\n      }\n    })\n  }else if(sdy == \"SDY404\" && name == \"young\"){\n    xd <- sapply(df[[input_col]], FUN = function(x){\n      if(is.na(x)){\n        return(NA)\n      }else if(round(x, digits = 7) < round(xq[[1]], digits = 7)){\n        return(0)\n      }else if(round(x, digits = 7) > round(xq[[2]], digits = 7)){\n        return(2)\n      }else{\n        return(1)\n      }\n    })\n  }else{\n    xd <- sapply(df[[input_col]], FUN = function(x){\n      if(is.na(x)){\n        return(NA)\n      }else if(round(x, digits = 7) <= round(xq[[1]], digits = 7)){\n        return(0)\n      }else if(round(x, digits = 7) >= round(xq[[2]], digits = 7)){\n        return(2)\n      }else{\n        return(1)\n      }\n    })\n  }\n  return(xd)\n}\n\n# Original discretize function from Yuri Kotliarov\n# NOTE: Does not return original results for $fc_res_max_d30\n# discretize <- function(df, input_col, low_perc) {\n#   x <- df[[input_col]]\n#   xq = quantile(x, c((low_perc/100), 1 - (low_perc/100)), na.rm=T)\n#   xd = ifelse(is.na(x),NA,1)\n#   xd[x<=xq[1]] = 0\n#   xd[x>=xq[2]] = 2\n#   return(xd)\n# }\n\n# for splitting participant_id string to remove sdy info\nsub_split <- function(x){\n  tmp <- (strsplit(x, split = \"[.]\"))\n  return(tmp[[1]][1])\n}\n\n# Drop columns by name\ndrop_cols <- function(df, cols_to_drop){\n  df <- df[ , !(names(df) %in% cols_to_drop)]\n  return(df)\n}\n\n#-----Main method--------------\n\n#' Function to generate HAI data table from ImmuneSpace Connection\n#'\n#' @param sdy Study\n#' @param output_dir output directory\n#' @export\nmakeHAI <- function(sdy, output_dir){\n\n  # SDY80's IS data is not the same as original because observations were only allowed\n  # if they had GE data as well (GEO standards).  The original data is available via\n  # Immport in the SQL dump.  However, for simplicity, the file preloaded in package.\n  if(sdy == \"SDY80\"){\n\n    firstpart <- c(\"cohort\", \"d0_std_norm_H1N1\", \"d0_std_norm_A_Uruguay\", \"d0_std_norm_A_Brisbane\",\n                  \"d0_std_norm_B_Brisbane\", \"fc_std_norm_H1N1\", \"fc_std_norm_A_Uruguay\",\n                  \"fc_std_norm_A_Brisbane\", \"fc_std_norm_B_Brisbane\")\n    last_names <- c(\"d0_norm_max\",\"fc_norm_max\",\"fc_norm_max_ivt\", \"d0_max\",\n                   \"fc_max\",\"fc_max_4fc\", \"fc_norm_max_d20\",\"fc_norm_max_d30\",\n                   \"fc_res_max\",\"fc_res_max_d20\",\"fc_res_max_d30\")\n    allnms <- c(firstpart, last_names)\n    tmpmat <- matrix(NA, ncol = 20, nrow = 64)\n    colnames(tmpmat) <- allnms\n\n    # This removes all subjects without original demo information, 223 has no IS sub id\n    # and is removed post-calculations\n    rawdata <- SDY80_rawtiterdata_v2 [ which(\n      (SDY80_rawtiterdata_v2$subject >=200 & SDY80_rawtiterdata_v2$subject <= 284)\n      ), ]\n\n    titer_data <- data.frame(rawdata, tmpmat)\n\n    # Adding cohort definition from Yuri comments re: code\n    old_subs <- c(212, 229, 232, 233, 244, 245, 250, 251, 260, 261, 273, 277, 280)\n    titer_data$cohort <- ifelse(titer_data$subject %in% old_subs, \"Old\", \"Young\")\n\n    subids <- titer_data$subject\n    strains <- c(\"H1N1\", \"A_Brisbane\", \"A_Uruguay\",\"B_Brisbane\")\n    cohorts <- c(\"Young\", \"Old\")\n    opts <- c(\"d0_\",\"fc_\")\n    str_d28_names <- \"\"\n    for(virus in strains){\n      str_d28_names <- c(str_d28_names, paste0(\"d28_\", virus))\n    }\n\n  }else{\n    con <- CreateConnection(sdy)\n    rawdata <- con$getDataset(\"hai\")\n\n    # Generate vectors from rawdata or instantiate variables based on\n    # nomenclature of original column headers\n    subids <- unique(rawdata$participant_id)\n    strains <- unique(rawdata$virus)\n    strains <- sapply(strains, FUN = function(x){\n      x <- gsub(\"\\\\.|\\\\/| |-|\\\\(|\\\\)\", \"_\", x)\n      return(x)\n    })\n    cohorts <- unique(rawdata$cohort)\n\n    days_collected <- c(0,28)\n    opts <- c(\"d0_\",\"fc_\")\n\n    # Setup df with columns, including those that will eventually be removed\n    str_names <- list()\n    str_d28_names <- list()\n    for(virus in strains){\n      for(opt in opts){\n        str_names <- c(str_names, paste0(opt, virus))\n        str_names <- c(str_names, paste0(opt, \"std_norm_\", virus))\n      }\n      str_d28_names <- c(str_d28_names, paste0(\"d28_\", virus))\n    }\n\n    first_names <- c(\"subject\",\"cohort\")\n    last_names <- c(\"d0_norm_max\",\"fc_norm_max\",\"fc_norm_max_ivt\", \"d0_max\",\n                    \"fc_max\",\"fc_max_4fc\", \"fc_norm_max_d20\",\"fc_norm_max_d30\",\n                    \"fc_res_max\",\"fc_res_max_d20\",\"fc_res_max_d30\")\n\n    numcol <- length(str_names) + length(str_d28_names) + length(first_names) + length(last_names)\n    titer_data <- data.frame(matrix(vector(),\n                                    nrow = 0,\n                                    ncol = numcol),\n                             stringsAsFactors = F)\n    colnames(titer_data) <- c(first_names, str_names, str_d28_names, last_names)\n\n    # Parse day 0 (initial) and day 28 (follow-up) titer data into df as basis for all future calculations.\n    # NOTE 1: Because the follow-up titer measurement is not always collected on day 28 exactly,\n    # it is assumed that any value greater than 0 represents the 28th day value if there is\n    # not a day 28 value present.\n    iterator <- 1\n    for(id in subids){\n      sub_data <- rawdata[which(rawdata$participant_id == id),]\n      valid <- sub_check(sub_data, names(strains))\n      if(valid){\n        titer_data[iterator,1] <- id\n        cohort_df <- rawdata[which(rawdata$participant_id == id),]\n        cohort_val <- unique(cohort_df$cohort)\n        titer_data[iterator,2] <- cohort_val\n        for(vir_name in names(strains)){\n          for(day in days_collected){\n            col_to_find <- paste0(\"d\", day, \"_\", strains[[vir_name]])\n            rowid <- which(rawdata$participant_id == id &\n                             rawdata$study_time_collected == day &\n                             rawdata$virus == vir_name)\n            if(length(rowid) == 0){\n              rowid <- which(rawdata$participant_id == id &\n                               rawdata$study_time_collected > 0 &\n                               rawdata$virus == vir_name)\n            }\n            if(length(rowid) > 1){\n              rowid <- rowid[[1]]\n            }\n            target_row <- rawdata[rowid, ]\n            titer_data[iterator, col_to_find] <- as.integer(target_row$value_reported)\n          }\n        }\n        iterator <- iterator + 1\n      }\n    }\n  }\n\n  # setup list to hold median and sd values for later use in calculations\n  glob_names <- c(\"d0_med\", \"d0_sd\",\"fc_med\", \"fc_sd\")\n  li <- vector(\"list\",length = length(strains))\n  names(li) <- strains\n  glob_vals <- list()\n  for(l in glob_names){\n    glob_vals[[l]] <- li\n  }\n\n  # calc median and sd for d0 cols\n  glob_vals <- med_sd_calc(\"d0_\", strains , glob_vals, titer_data)\n\n  # calc fold change\n  for(virus in strains){\n    d0_col <- paste0(\"d0_\", virus)\n    d28_col <- paste0(\"d28_\", virus)\n    fc_col <- paste0(\"fc_\", virus)\n    titer_data[,fc_col] <- titer_data[,d28_col]/titer_data[,d0_col]\n  }\n\n  # calc fold change med and sd\n  glob_vals <- med_sd_calc(\"fc_\", strains , glob_vals, titer_data)\n\n  # calc standardized and normalized value for each possibility of (d0,fc) x (strains)\n  # sd used in all non-SDY80 studies because more than 50% of subjects were defined\n  # as non-responders which causes denominator to be zero\n  for(ver in opts){\n    for(virus in strains){\n      std_norm_col <- paste0(ver, \"std_norm_\", virus)\n      tcol <- titer_data[[paste0(ver, virus)]]\n      if(sdy == \"SDY80\"){\n        robmed <- robust_med(tcol)\n        titer_data[std_norm_col] <- (tcol - robmed) / r_mad(tcol)\n        rep_ls <- titer_data[std_norm_col] == Inf\n        titer_data[std_norm_col][rep_ls] <- NaN\n      }else{\n        colmed <- glob_vals[[paste0(ver,\"med\")]][[virus]]\n        colsd <- glob_vals[[paste0(ver,\"sd\")]][[virus]]\n        titer_data[std_norm_col] <- (tcol - colmed) / colsd\n      }\n    }\n  }\n\n  # Assign snapshots of variables to global_env for use with mapply.\n  assign(\"gl_tdata\", titer_data, envir = .GlobalEnv)\n  assign(\"gl_strains\", strains, envir = .GlobalEnv)\n\n  # Select maxima for (d0,fc) x (\"\",\"std_norm\") columns\n  for(ver in opts){\n    titer_data[[paste0(ver,\"max\")]] <- mapply(max_select, titer_data$subject, ver)\n    titer_data[[paste0(ver,\"norm_max\")]] <- mapply(max_select, titer_data$subject, paste0(ver,\"std_norm_\"))\n  }\n\n  # determine fc_max_4fc, which is categorization based on fold change > 4\n  titer_data$fc_max_4fc <- unlist(lapply(titer_data$fc_max, FUN = function(x){\n    if(x > 4){return(1)}else{return(0)}\n    }))\n\n  # Inverse normal transformation of standardized/normalized max fold change column\n  # Done by quantile normalization on a modified ranking of observations\n  # fc_norm_max_ivt << provided from Yuri Kotliarov\n  ranked <- rank(titer_data$fc_norm_max, na.last = \"keep\")\n  P <- ranked / (sum(!is.na(ranked)) + 1) # +1 needed to avoid 0,1 values that generate inf, -inf\n  titer_data$fc_norm_max_ivt <- qnorm(P)\n\n  # Need to remove SDY80 subjects that have low flow results, NA for B-Brisbane, or not in original results\n  if(sdy == \"SDY80\"){\n    low_flow <- c(206, 226, 243, 247, 249, 252, 254, 263, 270, 275, 281, 282)\n    titer_data <- titer_data[ which(!(titer_data$subject %in% low_flow)), ]\n  }\n\n  # setup meta-list for possible titer tables based on cohorts: young, old, and combined are possible\n  submxs <- list()\n  submxs[[\"combined\"]] <- titer_data\n\n  # Generate subset matrices based on age and perform statistical work on each separately\n  # SDY212 and the other studies use different nomenclature for categorization, therefore\n  # need to check against lists\n  yng_ls <- c(\"Cohort_1\", \"Young adults 21-30 years old\", \"Young\")\n  old_ls <- c(\"Cohort_2\", \"Cohort2\", \"Older adults >= 65 years old\", \"healthy adults, 50-74 yo\", \"Old\")\n  for(coh in cohorts){\n    if(coh %in% yng_ls){\n      submxs[[\"young\"]]  <- titer_data[which(titer_data$cohort == coh),]\n    }else if(coh %in% old_ls){\n      if(sdy != \"SDY67\"){\n        submxs[[\"old\"]]  <- titer_data[which(titer_data$cohort == coh),]\n      }else{\n        # SDY67-old is only subjects over 60 yrs old.  These subject IDs are from the demographic file.\n        subs_keep <-  c(\"SUB113453\", \"SUB113458\", \"SUB113460\", \"SUB113461\", \"SUB113463\", \"SUB113464\",\n                        \"SUB113466\", \"SUB113467\", \"SUB113468\", \"SUB113470\", \"SUB113471\", \"SUB113486\",\n                        \"SUB113492\", \"SUB113493\", \"SUB113494\", \"SUB113495\", \"SUB113496\", \"SUB113497\",\n                        \"SUB113499\", \"SUB113500\", \"SUB113501\", \"SUB113502\", \"SUB113503\", \"SUB113504\",\n                        \"SUB113505\", \"SUB113508\", \"SUB113509\", \"SUB113510\", \"SUB113512\", \"SUB113516\",\n                        \"SUB113517\", \"SUB113525\", \"SUB113526\", \"SUB113527\", \"SUB113528\", \"SUB113529\",\n                        \"SUB113532\", \"SUB113533\", \"SUB113535\", \"SUB113536\", \"SUB113540\", \"SUB113541\",\n                        \"SUB113543\", \"SUB113545\", \"SUB113546\", \"SUB113547\", \"SUB113549\", \"SUB113553\",\n                        \"SUB113555\", \"SUB113556\", \"SUB113564\", \"SUB113571\", \"SUB113572\", \"SUB113574\",\n                        \"SUB113575\", \"SUB113577\", \"SUB113578\", \"SUB113580\", \"SUB113586\", \"SUB113593\",\n                        \"SUB113594\", \"SUB113595\", \"SUB113596\", \"SUB113599\", \"SUB113602\", \"SUB113603\",\n                        \"SUB113604\", \"SUB113605\", \"SUB113606\")\n        subs_keep <- sapply(subs_keep, FUN = function(x){\n          x <- paste0(x,\".67\")\n        })\n        submxs[[\"old\"]] <- titer_data[(titer_data$subject %in% subs_keep),]\n      }\n    }\n  }\n\n  # fc_res_max is generated by first binning the subjects' d0_norm_max data\n  # according to a manual selection and then normalizing/standardizing\n  # the inverse normal transformation values within those bins.\n  # This code is based on Yuri Kotliarov's work.\n  SDY404_bins <- list(c(1,5),c(0.25,1,5),c())\n  SDY212_bins <- list(c(0.01),c(0.05),c(0.01))\n  # Although SDY400 only shows bins 1,5 on google drive png, it has two NaN vals indicative of\n  # single member bins, therefore third bin was added (6) in young / combined. Old appeared to\n  # need very different bins.\n  SDY400_bins <- list(c(1,5,6),c(1,5,6),c(0.1,3))\n  SDY63_bins <- list(c(2,6),c(2),c(2))\n  # SDY67 / 80 not derived from pngs in HIPC google drive, but rather determined by following method:\n  # file <- fread(\"original_hai_tbl\")\n  # df <- data.frame(file$fc_res_max,file$fc_norm_max_ivt,file$d0_norm_max)\n  # df <- df[order($fc_norm_max_ivt,$d0_norm_max),]\n  # By looking at where ivt is the same but fc_res_max was different, one can guess that they\n  # were in different bins and estimate the cutoff points by looking at the d0_norm_max value.\n  SDY67_bins <- list(c(0.1,0.5,1.5,4,6),c(),c(0.1,0.5,1.5,6))\n  SDY80_bins <- list(c(-10,1,50),c(-10,1,50),c()) # From Yuri's code\n\n  bname <- paste0(sdy,\"_bins\")\n  bins <- get(bname)\n  names(bins) <- c(\"combined\", \"young\", \"old\")\n\n  for(name in names(submxs)){\n    df <- submxs[[name]]\n    tmp_mad <- r_mad(df$fc_norm_max_ivt)\n    df$bin <- cut(df$d0_norm_max,\n                  breaks = c(-Inf, bins[[name]], Inf),\n                  labels = 1:( length(bins[[name]]) + 1) )\n\n    # need count of bin members to force NA value for bins with < 3 members.\n    # Original code was in Matlab and may not have generated median / sd vals for < 3 groups.\n    df = df %>%\n      group_by(bin) %>%\n      dplyr::mutate(count = n()) %>% # MUST name 'dplyr' in front of mutate to get dplyr::n()\n      ungroup()\n\n    if(sdy == \"SDY80\"){\n      df = df %>%\n        group_by(bin) %>%\n        mutate(fc_res_max = (fc_norm_max_ivt - median(fc_norm_max_ivt)) / r_mad(fc_norm_max_ivt)) %>%\n        ungroup()\n\n      df$fc_res_max <- ifelse(df$fc_res_max %in% c(Inf, NA), NaN, df$fc_res_max)\n    }else{\n      df = df %>%\n        group_by(bin) %>%\n        mutate(fc_res_max =\n                 ifelse( count > 2 | sdy == \"SDY63\", # SDY63 Old allows a 2 count group to be processed\n                         (fc_norm_max_ivt - median(fc_norm_max_ivt, na.rm=T)) / sd(fc_norm_max_ivt, na.rm=T),\n                         NaN)) %>%\n        ungroup()\n    }\n\n\n    # discretize for all combinations of (\"fc_norm_max\",\"fc_res_max\") x (\"d20\",\"d30\")\n    in_cols <- c(\"fc_norm_max\", \"fc_res_max\")\n    in_percs <- c(20, 30)\n    for(cl in in_cols){\n      for(perc in in_percs){\n        targ_col <- paste0(cl,\"_d\", perc)\n        df[[targ_col]] <- discretize(df, cl, perc, sdy, name)\n      }\n    }\n\n    # Remove d28, bin, and cohort columns b/c not present in results of original manual versions.\n    df <- drop_cols(df, c(str_d28_names, \"bin\", \"cohort\", \"count\"))\n\n\n    # output tibble / df as a tab-delimited file\n    base <- \"_hai_titer_table.txt\"\n    fname <- \"\"\n\n    if(sdy == \"SDY80\"){\n      fname <- paste0(\"CHI-nih_\", name, base)\n      id_hsh <- hash(SDY80_IDmap$bioSampleID, SDY80_IDmap$participantID)\n      df$subject <- sapply(df$subject, FUN = function(x){\n        val <- id_hsh[[as.character(x)]]\n        return(ifelse(is.null(val), 223, val))\n      })\n      df <- df[-which(df$subject == 223), ] # because not able to map 223 to IS ID\n    }else{\n      fname <- paste0(sdy, \"_\", name, base)\n    }\n\n    df$subject <- unlist(lapply(df$subject, sub_split))\n\n    # row.names to NULL so that datasets.R does not read in row number as subjectID\n    write.table(df, file = file.path(output_dir,fname),\n                sep = \"\\t\",\n                col.names = TRUE,\n                row.names = FALSE)\n  }\n}\n\n\n\n",
    "created" : 1491603397463.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "934412459",
    "id" : "9DDB3270",
    "lastKnownWriteTime" : 1488481158,
    "last_content_update" : 1488481158,
    "path" : "~/R/ImmSigPkg/R/EH_MakeHAI_f.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}